# Projeto de Banco de Dados 2 â€“ Engenharia de Dados com Data Lake e PySpark

## ğŸ“Œ DescriÃ§Ã£o

Este projeto foi desenvolvido para a disciplina **Banco de Dados 2**, com o objetivo de aplicar conceitos de **Engenharia de Dados** utilizando um **Data Lake** e ferramentas do ecossistema **Apache Spark (PySpark)**.

A proposta Ã© construir uma arquitetura que permita **armazenar, processar e analisar dados em larga escala**, explorando tÃ©cnicas modernas de ingestÃ£o, transformaÃ§Ã£o e organizaÃ§Ã£o de dados para anÃ¡lise.

## ğŸ¯ Objetivos

* Compreender os conceitos de **Data Lake** e sua importÃ¢ncia para Big Data.
* Implementar pipelines de ingestÃ£o e transformaÃ§Ã£o de dados utilizando **PySpark**.
* Organizar dados em diferentes camadas do Data Lake (**Raw, Processed, Curated**).
* Realizar consultas e anÃ¡lises exploratÃ³rias sobre os dados tratados.
* Demonstrar boas prÃ¡ticas de **Engenharia de Dados** em um ambiente acadÃªmico.

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.x**
* **Apache Spark / PySpark**
* **Data Lake (estrutura em camadas Raw, Processed, Curated)**
* **Hadoop HDFS ou sistema de arquivos local** (dependendo da configuraÃ§Ã£o do ambiente)
* **Jupyter Notebook** para anÃ¡lises exploratÃ³rias
* **Git/GitHub** para versionamento

## ğŸ“‚ Estrutura do Projeto

```
ğŸ“¦ projeto-bd2-datalake
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw/          # Dados brutos
â”‚   â”œâ”€â”€ processed/    # Dados processados
â”‚   â””â”€â”€ curated/      # Dados prontos para consumo
â”œâ”€â”€ notebooks/        # Jupyter Notebooks com anÃ¡lises e ETL
â”œâ”€â”€ scripts/          # Scripts PySpark para ingestÃ£o e transformaÃ§Ã£o
â”œâ”€â”€ docs/             # DocumentaÃ§Ã£o do projeto
â””â”€â”€ README.md
```

## âš™ï¸ Funcionalidades

* IngestÃ£o de dados em formato **CSV/JSON/Parquet** para o Data Lake.
* Processamento de dados brutos com **PySpark** (limpeza, padronizaÃ§Ã£o, enriquecimento).
* Armazenamento otimizado em formatos de alto desempenho (**Parquet/Delta**).
* Consultas analÃ­ticas sobre dados tratados.

## ğŸš€ Como Executar o Projeto

1. **Clone o repositÃ³rio**

```bash
git clone h[ttps://github.com/jeffersonsenaa/sbd2-engenharia-de-dados-2025.2.git](https://github.com/JeffersonSenaa/SBD2---Engenharia-de-Dados---2025.2/)
cd projeto-bd2-datalake
```

2. **Crie o ambiente e instale dependÃªncias**

```bash
pip install -r requirements.txt
```

3. **Inicie o Spark** e execute os notebooks/scripts para processar os dados.

```bash
pyspark
```

## ğŸ“Š Exemplos de Uso

* IngestÃ£o de dados de vendas e clientes para o Data Lake.
* TransformaÃ§Ã£o e cÃ¡lculo de mÃ©tricas como **ticket mÃ©dio, clientes ativos, vendas por regiÃ£o**.
* CriaÃ§Ã£o de uma camada **curated** com dados prontos para BI.

## ğŸ“– Aprendizados

Durante o desenvolvimento do projeto, serÃ£o explorados:

* DiferenÃ§as entre **Data Warehouse x Data Lake**.
* EstruturaÃ§Ã£o de pipelines ETL/ELT.
* OtimizaÃ§Ã£o de armazenamento e consulta em Big Data.
* AplicaÃ§Ãµes prÃ¡ticas de **Engenharia de Dados**.

## ğŸ‘¨â€ğŸ’» Autores

